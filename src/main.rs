use std::sync::Arc;
use dashmap::DashMap;
use tokio::sync::Mutex;

use call_agent::chat::{
    client::{ModelConfig, OpenAIClient, OpenAIClientState},
    prompt::{Message, MessageContext},
};
use observer::{prefix, tools::{self, web_scraper}};
use tools::{get_time::GetTime, memory::MemoryTool, web_scraper::WebScraper};

use serenity::{all::{CreateCommand, CreateCommandOption, CreateEmbed, CreateInteractionResponse, CreateInteractionResponseMessage, EditInteractionResponse}, async_trait};
use serenity::model::gateway::Ready;
use serenity::model::prelude::*;
use serenity::prelude::*;

pub struct InputMessage {
    pub content: String,
    pub name: String,
    pub message_id: String,
    pub reply_to: Option<String>,
}
// å„ãƒãƒ£ãƒ³ãƒãƒ«ã®ä¼šè©±å±¥æ­´ï¼ˆstateï¼‰ã‚’ä¿æŒã™ã‚‹æ§‹é€ ä½“
pub struct ChannelState {
    // ä¸¦åˆ—å‡¦ç†ã®ãŸã‚ã€prompt_stream ã‚’ Mutex ã§ä¿è­·ã™ã‚‹
    prompt_stream: Mutex<OpenAIClientState<'static>>,
}

impl ChannelState {
    fn new(client: &Arc<OpenAIClient>) -> Self {
        // æ–°ã—ã„ PromptStream ã‚’ç”Ÿæˆã™ã‚‹
        let prompt_stream = client.create_prompt();
        // Extend lifetime to 'static; safe because client lives for the entire duration of the program
        let prompt_stream: OpenAIClientState<'static> = unsafe { std::mem::transmute(prompt_stream) };
        Self {
            prompt_stream: Mutex::new(prompt_stream),
        }
    }

    pub async fn ask(&self, message: InputMessage) -> String {
        let mut prompt_stream = {
            let prompt_stream = self.prompt_stream.lock().await;
            (*prompt_stream).clone()
        };

        let content = format!("id:{};\n{}", message.message_id, message.content);

        let prompt = vec![Message::User {
            content: vec![MessageContext::Text(content)],
            name: Some(message.name),
        }];
        prompt_stream.add(prompt).await;

        for _ in 0..5 {
            let _ = prompt_stream.generate_can_use_tool(None).await;
            let res = match prompt_stream.last().await {
                Some(r) => r,
                None => return "AIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ".to_string(),
            };

            println!("{:?}", res);

            match res {
                Message::Tool { .. } => continue,
                Message::Assistant { ref content, .. } => {
                    if let Some(MessageContext::Text(text)) = content.first() {
                        return text.replace("\\n", "\n");
                    } else {
                        return format!("{:?}", res);
                    }
                }
                _ => return "AIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ".to_string(),
            }
        }
        let _ = prompt_stream.generate(None).await;
        let res = prompt_stream.last().await.unwrap();
        println!("{:?}", res);
        match res {
            Message::Assistant { ref content, .. } => {
                if let Some(MessageContext::Text(text)) = content.first() {
                    return text.replace("\\n", "\n");
                } else {
                    return format!("{:?}", res);
                }
            }
            _ => return "AIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ".to_string(),
        }
    }

    pub async fn deep_search(&self, message: InputMessage, try_count: usize) -> String {
        let mut prompt_stream = {
            let prompt_stream = self.prompt_stream.lock().await;
            (*prompt_stream).clone()
        };

        let content = format!("id:{};\n{}", message.message_id, message.content);

        let prompt = vec![Message::User {
            content: vec![MessageContext::Text(content)],
            name: Some(message.name),
        }];

        let systemprompt = vec![Message::Developer {
            content: "p, h1, h2, h3, h4, h5, a, video, imgã‚¿ã‚°ã‚’æŒ‡å®šã—ã¦ãƒªãƒ³ã‚¯ã‚’ãŸã©ã£ãŸã‚Šã—ã¦å†…å®¹ã‚’å®Œå…¨ã«æŠŠæ¡ã™ã‚‹ã‚ˆã†ã« ã¾ãšã¯åˆã‚ã®ãƒšãƒ¼ã‚¸ã‚ã‚‹ãƒªãƒ³ã‚¯ãªã©ã‚’ãŸã©ã£ã¦ã„ãã‚ˆã†ã« ãã®ãƒšãƒ¼ã‚¸ã®è¦ç´ ã‚’ã™ã¹ã¦ç¢ºèªã—ãŸã‚‰ ãã®ãƒšãƒ¼ã‚¸ã®ãƒªãƒ³ã‚¯ã®ãƒšãƒ¼ã‚¸ã‚’ç¶šã‘ã¦ã¿ã¦ã„ãã‚ˆã†ã« ãªã«ã‚‚è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ–¹æ³•ã‚’å¤‰ãˆã‚‹ã‹ã€ã»ã‹ã®ãƒšãƒ¼ã‚¸ã‚’è¦‹ã«è¡Œã£ã¦ãã ã•ã„".to_string(),
            name: Some("Observer".to_string()),
        }];
        prompt_stream.add(prompt).await;
        prompt_stream.add(systemprompt).await;

        for _ in 0..try_count {
            let _ = prompt_stream.generate_with_tool(None, "web_scraper").await;
            let res = match prompt_stream.last().await {
                Some(r) => r,
                None => return "AIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ".to_string(),
            };

            println!("{:?}", res);

            match res {
                Message::Tool { .. } => continue,
                Message::Assistant { ref content, .. } => {
                    if let Some(MessageContext::Text(text)) = content.first() {
                        return text.replace("\\n", "\n");
                    } else {
                        return format!("{:?}", res);
                    }
                }
                _ => return "AIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ".to_string(),
            }
        }
        prompt_stream.add(
            vec![Message::Developer {
                content: "æ¤œç´¢ã§ã¿ã¤ã‘ãŸå†…å®¹ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„".to_string(),
                name: Some("Observer".to_string()),
            }]
        ).await;
        let _ = prompt_stream.generate(None).await;
        let res = prompt_stream.last().await.unwrap();
        println!("{:?}", res);
        match res {
            Message::Assistant { ref content, .. } => {
                if let Some(MessageContext::Text(text)) = content.first() {
                    return text.replace("\\n", "\n");
                } else {
                    return format!("{:?}", res);
                }
            }
            _ => return "AIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ".to_string(),
        }
    }

    pub async fn add_message(&self, message: InputMessage) {
        let mut prompt_stream = self.prompt_stream.lock().await;

        let content = format!("id:{};\n{}", message.message_id, message.content);

        let prompt = vec![Message::User {
            content: vec![MessageContext::Text(content)],
            name: Some(message.name),
        }];
        prompt_stream.add(prompt).await;
    }
}

struct Handler {
    // Handlerã«1ã¤ã®OpenAIClientã‚’ä¿æŒ
    base_client: Arc<OpenAIClient>,
    // å„ãƒãƒ£ãƒ³ãƒãƒ«ã”ã¨ã®çŠ¶æ…‹ï¼ˆä¼šè©±å±¥æ­´ï¼‰ã‚’ä¿æŒï¼ˆDashMapã¯ä¸¦åˆ—å‡¦ç†å¯èƒ½ï¼‰
    channels: DashMap<ChannelId, Arc<ChannelState>>,
}

#[async_trait]
impl EventHandler for Handler {
    /// ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé€ä¿¡ã•ã‚ŒãŸã¨ãã®å‡¦ç†
    async fn message(&self, _ctx: Context, msg: serenity::all::Message) {
        let state = self
            .channels
            .entry(msg.channel_id)
            .or_insert_with(|| {
                Arc::new(ChannelState::new(&self.base_client))
            })
            .clone();

        let message = InputMessage {
            content: msg.content,
            name: msg.author.name.clone(),
            message_id: msg.id.to_string(),
            reply_to: None,
        };

        state.add_message(message).await;
    }

    async fn interaction_create(&self, ctx: Context, interaction: Interaction) {
        if let Interaction::Command(command) = interaction {
            match command.data.name.as_str() {
                "ping" => {
                    let response_data = CreateInteractionResponseMessage::new()
                    .content("Pong! ğŸ“");

                    let response = CreateInteractionResponse::Message(response_data);

                    if let Err(why) = command.create_response(&ctx.http, response).await {
                        println!("Failed to respond to ping: {:?}", why);
                    }
                }

                "ask" => {
                    // è€ƒãˆä¸­
                    let defer_response = CreateInteractionResponse::Defer(
                        CreateInteractionResponseMessage::new()
                    );
                    if let Err(why) = command.create_response(&ctx.http, defer_response).await {
                        println!("Failed to send Defer response: {:?}", why);
                        return;
                    }

                    let question = command.data.options[0].value.as_str().unwrap();
                    let state = self
                        .channels
                        .entry(command.channel_id)
                        .or_insert_with(|| {
                            Arc::new(ChannelState::new(&self.base_client))
                        })
                        .clone();

                    let message = InputMessage {
                        content: question.to_string(),
                        name: command.user.name.clone(),
                        message_id: "".to_string(),
                        reply_to: None,
                    };

                    let answer_text = state.ask(message).await;
                    
                    let response = EditInteractionResponse::new()
                        .content(&answer_text);

                    if let Err(why) = command.edit_response(&ctx.http, response).await {
                        println!("Failed to respond to ask: {:?}", why);
                    }
                }

                "deep_search" => {
                    // è€ƒãˆä¸­
                    let defer_response = CreateInteractionResponse::Defer(
                        CreateInteractionResponseMessage::new()
                    );
                    if let Err(why) = command.create_response(&ctx.http, defer_response).await {
                        println!("Failed to send Defer response: {:?}", why);
                        return;
                    }
                    let question = command.data.options[0].value.as_str().unwrap();
                    let try_count = command.data.options[1].value.as_i64().unwrap_or(10) as usize;
                    let state = self
                        .channels
                        .entry(command.channel_id)
                        .or_insert_with(|| {
                            Arc::new(ChannelState::new(&self.base_client))
                        })
                        .clone();

                    let message = InputMessage {
                        content: question.to_string(),
                        name: command.user.name.clone(),
                        message_id: "".to_string(),
                        reply_to: None,
                    };

                    let answer_text = state.deep_search(message, try_count).await;

                    let response = EditInteractionResponse::new()
                        .content(&answer_text);

                    if let Err(why) = command.edit_response(&ctx.http, response).await {
                        println!("Failed to respond to ask: {:?}", why);
                    }
                }


                _ => println!("Unknown command: {}", command.data.name),
            }
        }
    }

    /// Bot ãŒèµ·å‹•ã—ãŸã¨ãã®å‡¦ç†
    async fn ready(&self, ctx: Context, ready: Ready) {
        println!("{} is connected!", ready.user.name);

        // ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚³ãƒãƒ³ãƒ‰ã‚’ç™»éŒ²
        Command::set_global_commands(&ctx.http, vec![
            CreateCommand::new("ping")
                .description("Pong! ğŸ“")
                .add_option(
                    CreateCommandOption::new(CommandOptionType::String, "è¿”ã™å†…", "Pong! ğŸ“")
                        .required(true)
                ),
            CreateCommand::new("ask")
                .description("observerã«è©±ã—ã‹ã‘ã‚‹")
                .add_option(
                    CreateCommandOption::new(CommandOptionType::String, "å†…å®¹", "Observerã«è³ªå•ã™ã‚‹å†…å®¹")
                        .required(true)
                ),
            CreateCommand::new("deep_search")
                .description("observerã«æ·±ã„ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’ã•ã›ã‚‹")
                .add_option(
                    CreateCommandOption::new(CommandOptionType::String, "å†…å®¹", "Observerã«è³ªå•ã™ã‚‹å†…å®¹")
                        .required(true)
                )
                .add_option(
                    CreateCommandOption::new(CommandOptionType::Integer, "è©¦è¡Œå›æ•°", "è©¦è¡Œå›æ•°")
                        .required(false)
                        .max_int_value(20)
                        .min_int_value(1)
                )
            ])
        .await
        .expect("Failed to create global command");
    }
}

#[tokio::main]
async fn main() {
    // Discord Bot ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
    let token = prefix::settings::DISCORD_TOKEN;

    // ãƒ¢ãƒ‡ãƒ«è¨­å®š
    let conf = ModelConfig {
        model: "gpt-4o-mini".to_string(),
        model_name: None,
        parallel_tool_calls: None,
        temperature: Some(0.5),
        max_completion_tokens: Some(4000),
        reasoning_effort: None,
        presence_penalty: Some(0.0),
        strict: Some(false),
        top_p: Some(1.0),
    };

    // åŸºæœ¬ã¨ãªã‚‹ OpenAIClient ã‚’ç”Ÿæˆã—ã€ãƒ„ãƒ¼ãƒ«ã‚’å®šç¾©
    let mut base_client = OpenAIClient::new(
        prefix::settings::model::MAIN_MODEL_ENDPOINT,
        Some(prefix::settings::model::MAIN_MODEL_API_KEY),
    );
    base_client.def_tool(Arc::new(GetTime::new()));
    base_client.def_tool(Arc::new(WebScraper::new()));
    base_client.def_tool(Arc::new(MemoryTool::new()));
    base_client.set_model_config(&conf);
    let base_client = Arc::new(base_client);

    let mut c = base_client.create_prompt();
    c.add(vec![Message::User {
        content: vec![MessageContext::Text("ã“ã‚“ã«ã¡ã¯".to_string())],
        name: Some("Observer".to_string()),
    }])
    .await;

    let rs = c.generate(None).await;

    println!("{:?}", rs);

    let r = c.last().await.unwrap();

    print!("{:?}", r);


    // Bot ã®ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆè¨­å®šï¼ˆMESSAGE_CONTENT ã‚’å«ã‚€ï¼‰
    let intents = GatewayIntents::GUILD_MESSAGES | GatewayIntents::MESSAGE_CONTENT;
    let mut client = Client::builder(&token, intents)
        .event_handler(Handler {
            base_client,
            channels: DashMap::new(),
        })
        .await
        .expect("Error creating client");

    if let Err(e) = client.start().await {
        println!("Client error: {:?}", e);
    }
}