
use std::fmt::Display;

use openai_dive::v1::resources::{response::{request::ResponseParametersBuilder, response::ResponseReasoning}, shared::ReasoningEffort};

#[derive(Clone)]
pub struct Config {
    pub discord_token: String,
    pub openai_api_key: String,
    pub system_prompt: String,
    pub rale_limit_window_size: u64,
    pub rate_limit_sec_per_cost: u64,
    pub web_server_host: [u8; 4],
    pub web_server_local_ip: [u8; 4],
    pub web_server_port: u16,
    pub admin_users: Vec<u64>,
}

impl Config {
    pub fn new() -> Self {
        let discord_token =
            std::env::var("DISCORD_TOKEN").expect("DISCORD_TOKEN must be set");
        let openai_api_key =
            std::env::var("OPENAI_API_KEY").expect("OPENAI_API_KEY must be set");
        let system_prompt =
            std::env::var("SYSTEM_PROMPT").unwrap_or_else(|_| 
"ä¸Šè¨˜ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯Discordå†…ã§ã®ä¼šè©±ã§ã™ã€‚
ã‚ãªãŸã¯ Discord ã® BOTã€ŒObserverã€ã§ä»¥ä¸Šã®ä¼šè©±ã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚
è‡ªç„¶ã«ä¼šè©±ã—ã€çŸ¥è­˜ç³»ã®è©±é¡Œã§ã¯æƒ…å ±æºã®ç¢ºèªã¨æœ€æ–°æ€§ã®ãƒã‚§ãƒƒã‚¯ã‚’å¿…ãšè¡Œã†ã€‚
æ›–æ˜§ãªæƒ…å ±ã¯èª¿ã¹ã€å†…å®¹ã‚’æé€ ã—ãªã„ã€‚å¿…è¦ãªã‚‰è³ªå•ã—ã¦ã‚‚ã‚ˆã„ã€‚
æƒ…å ±ã¯è«–ç†çš„ã«æ•´ç†ã—ã€å¿…è¦ãŒã‚ã‚Œã° tool ã‚’ä½¿ã£ã¦èª¿æŸ»ã™ã‚‹
tool ã®çµæœã¯ç›¸æ‰‹ã«è¦‹ãˆãªã„ãŸã‚ã€å¿…ãšå†…å®¹ã‚’æ›¸ãå‡ºã™
éåº¦ã«è‡ªä¿¡ã‚’æŒãŸãšã€æ…é‡ã«åˆ¤æ–­ã™ã‚‹
â€œ!â€ ã‚„ emoji ã¯æ§ãˆã‚ã«
ã‚¹ãƒ¬ãƒƒãƒ‰ä½œæˆã¯äº‹å‰ã«ææ¡ˆ
æ•°å­¦ã®èª¬æ˜ã§ã¯ latex_expr_render ã‚’ä½¿ã†
discord_send_message ã§ãƒ†ã‚­ã‚¹ãƒˆâ†’æ•°å¼ã®é †ãªã©ã€æ®µéšçš„ã«é€ã‚‹ã®ã‚‚å¯
å†—é•·ãªèª¬æ˜ã‚’é¿ã‘ã€ç«¯çš„ã«
ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯ ğŸ« ğŸ˜±ğŸ‘ğŸ‘ˆğŸ¤” ã‚’ä¸­å¿ƒã«
ä¸€èªã§ååˆ†ãªã‚‰ä¸€èªã§è¿”ã™ï¼ˆä¾‹:ã€Œã†ã‚“ã€ã€Œãã†ã€ã€Œã¯ï¼Ÿã€ã€Œ???ã€ã€Œã«ã‚ƒã‚“ã€ã€Œ?ã€ã€Œ...ã€ï¼‰
ã‚¹ãƒ©ãƒ³ã‚°ã¯é©åº¦ã«ã€‚åŸºæœ¬ã¯é™ã‹ãƒ»è«–ç†çš„ãƒ»è½ã¡ç€ã„ãŸå£èª¿ã€ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã« æ•¬èªã¯å¿…è¦ãªæ™‚ã®ã¿ã§
ä¸€äººç§°ã¯ã€Œç§ã€ã‹ãª ã¾ãè‡ªç”±ã«
é‡è¦: å‘¨å›²ã®å£èª¿ã‚’çœŸä¼¼ã™ã‚‹ã‚ˆã†ã«ã€‚ã“ã‚Œã¯ã¨ã¦ã‚‚ã‚ˆã„çµæœã‚’ç”Ÿã¿ã¾ã™ã€‚ ãƒ¦ãƒ¼ãƒ¢ã‚¢ã‚’å¤§äº‹ã« èˆˆå‘³æ·±ã„ã‚‚ã®ã«ã¯ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ å¿œç­”ãŒé•·ããªã‚Šã™ããªã„ã‚ˆã†ã«ãƒ†ãƒ³ãƒã‚ˆã
tool_call ã§ãªã„é€šå¸¸ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚‹ã¨æ¨è«–çµ‚äº†ã™ã‚‹ã®ã§æ³¨æ„ã‚’".to_string());
        Config {
            discord_token,
            openai_api_key,
            system_prompt,
            rale_limit_window_size: 16200,
            rate_limit_sec_per_cost: 900,
            web_server_host: [0, 0, 0, 0],
            web_server_local_ip: [192, 168, 0, 26],
            web_server_port: 96,
            admin_users: vec![855371530270408725]
        }
    }
}

#[derive(Debug, Clone)]
pub enum Models {
    Gpt5Mini,
    Gpt5Nano,
    Gpt5dot1,
    O4Mini,
    O3,
    Gpt5dot1CodexMini
}

impl Into<String> for Models {
    fn into(self) -> String {
        match self {
            Models::Gpt5Mini => "gpt-5-mini".to_string(),
            Models::Gpt5Nano => "gpt-5-nano".to_string(),
            Models::Gpt5dot1 => "gpt-5.1".to_string(),
            Models::O4Mini => "o4-mini".to_string(),
            Models::O3 => "o3".to_string(),
            Models::Gpt5dot1CodexMini => "gpt-5.1-codex-mini".to_string(),
        }
    }
}

impl Display for Models {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let model_str: String = self.clone().into();
        write!(f, "{}", model_str)
    }
}

impl From<String> for Models {
    fn from(s: String) -> Models {
        match s.as_str() {
            "gpt-5-mini" => Models::Gpt5Mini,
            "gpt-5-nano" => Models::Gpt5Nano,
            "gpt-5.1" => Models::Gpt5dot1,
            "o4-mini" => Models::O4Mini,
            "o3" => Models::O3,
            "gpt-5.1-codex-mini" => Models::Gpt5dot1CodexMini,
            _ => Models::Gpt5Nano, // default
        }
    }
}

impl Models {
    pub fn list() -> Vec<Models> {
        vec![
            Models::Gpt5Mini,
            Models::Gpt5Nano,
            Models::Gpt5dot1,
            Models::O4Mini,
            Models::O3,
            Models::Gpt5dot1CodexMini
        ]
    }

    pub fn rate_cost(&self) -> u64 {
        match self {
            Models::Gpt5Mini => 1,
            Models::Gpt5Nano => 2,
            Models::Gpt5dot1 => 6,
            Models::O4Mini => 3,
            Models::O3 => 6,
            Models::Gpt5dot1CodexMini => 2,
        }
    }

    pub fn to_parameter(&self) -> ResponseParametersBuilder {
        match self {
            Models::Gpt5Mini => {
                ResponseParametersBuilder::default().model("gpt-5-mini")
                .reasoning(
                    ResponseReasoning {
                        effort: Some(ReasoningEffort::Low),
                    }
                ).clone()
            }
            Models::Gpt5Nano => {
                ResponseParametersBuilder::default().model("gpt-5-nano")
                .reasoning(
                    ResponseReasoning {
                        effort: Some(ReasoningEffort::Low),
                    }
                ).clone()
            }
            Models::Gpt5dot1 => { 
                ResponseParametersBuilder::default().model("gpt-5.1")
                .reasoning(
                    ResponseReasoning {
                        effort: Some(ReasoningEffort::Low),
                    }
                ).clone()
            }
            Models::O4Mini => { 
                ResponseParametersBuilder::default().model("o4-mini")
                .reasoning(
                    ResponseReasoning {
                        effort: Some(ReasoningEffort::Low),
                    }
                ).clone()
            }
            Models::O3 => { 
                ResponseParametersBuilder::default().model("o3")
                .reasoning(
                    ResponseReasoning {
                        effort: Some(ReasoningEffort::Low),
                    }
                ).clone()
            }
            Models::Gpt5dot1CodexMini => { 
                ResponseParametersBuilder::default().model("gpt-5.1-codex-mini")
                .reasoning(
                    ResponseReasoning {
                        effort: Some(ReasoningEffort::Low),
                    }
                ).clone()
            }
        }
    }
}